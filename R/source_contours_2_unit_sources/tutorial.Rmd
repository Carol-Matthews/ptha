```{r cache=FALSE, eval=TRUE, echo=FALSE}
knitr::read_chunk(
    'produce_unit_sources.R', 
    labels=c('initialise'), 
    from=c('## ---- initialise ----'), 
    to=c('## ---- takeCommandLineParameter ----'),
    from.offset=1,
    to.offset=-1)
```

# **Making unit sources from contours defining the earthquake source geometry**
------------------------------------------------------------------------------

*Note: Do not edit the tutorial.md file directly, as it is auto-generated by the
corresponding tutorial.Rmd file. Edit the latter instead.*

# Background

This document explains how to use the script
*'[produce_unit_sources.R](produce_unit_sources.R)'* to convert earthquake
source contours (defining an irregularly dipping surface on which earthquake
slip can occur) into tsunami unit sources. 

You may find it helpful to directly read
*'[produce_unit_sources.R](produce_unit_sources.R)'* first (or instead),
particularly if you have programming experience. All functions used therein are
documented in the rptha package or other packages, and so R's help system can
be consulted for details. 

In a typical application you would make a copy of
*'[produce_unit_sources.R](produce_unit_sources.R)'* in a new working
directory, and then edit the script parameters as required before running. You
might also edit the code, depending on your needs.

To create a set of unit sources, you first need to have a set of source
contours. These describe the earthquake source geometry, which we will
discretize into unit sources. The source contours need to be in line shapefile
format, where each line corresponds to a contour with given depth. The actual
depths are stored in the shapefile attribute table, with an attribute name
'level' giving the depth in km.  Lon-lat coordinates should be used (WGS84).

The source contours will be used to define the unit sources, so they should
only cover areas where you want unit sources to be made. On a typical
subduction zone they would extend from the subduction zone trench to a depth
of around 50 km, though the latter depth may vary (see e.g.  Berryman et al.,
2015). 

The unit sources will be arranged in a logically rectangular grid which covers
the source contours. The number of unit-sources down-dip and along-strike is chosen
based on the user-provided value for the desired unit-source length and width. 

# Example data

In this example we work with some contours for the Alaska source-zone. This is
situated at the eastern end of the Aleutians-Alaska subduction interface in the
North Pacific. The code below demonstrates how to read them in R and make a basic plot. 

**Note the code in this section is not required when using
*'[produce_unit_sources.R](produce_unit_sources.R)'* -- however, we include
this to demonstrate the input data requirements**

```{r, eval=TRUE, echo=TRUE}
# Read the shapefile
library(rgdal)
alaska = readOGR(dsn='CONTOURS/alaska.shp', layer='alaska')

# Print some information about it
summary(alaska)

# There should be a single attribute named 'level' containing the contour depths
names(alaska)
print(alaska$level)

# Make a quick plot of the input data
spplot(alaska, main='Alaska sourcezone contours giving the interface depth in km', 
    scales=list(draw=TRUE), aspect='iso')
```

# Input parameters

The code below comes directly from
*'[produce_unit_sources.R](produce_unit_sources.R)'*.

In typical usage of *'[produce_unit_sources.R](produce_unit_sources.R)'*, the
user would edit the input parameters to define the source contour filename(s),
the assumed earthquake rake, the desired unit-source length and width, the
resolution of the output raster, and some numerical parameters, the most
important of which are the sub-unit-source grid spacing.

If Kajiura filtering is to be applied, then the user must also provide an
elevation raster (in lon-lat coordinates, with elevation in m, and negative
value being below MSL). The input source zones should of course have longitudes
inside the extent of the raster (if they are off by 360 degrees then the code
will make the correction). Use of Kajiura filtering will cause the code to run
more slowly.

Note that more than one source-contour shapefile can be provided -- the code
will loop over them.

If you are running linux on a shared memory machine with multiple cores, then
you can run in parallel by setting MC_CORES to be a number greater than one. In
this case each core will run separate unit sources, until all are completed. 

```{r initialise, echo=TRUE}
```

# Running the script
Assuming the rptha package has been successfully installed, the script can be
run from within R using the syntax:

    source('produce_unit_sources.R', echo=TRUE, max.deparse.length=Inf)

where the `echo=TRUE` command prints the commands to the screen as they are
executed. 

Alternatively the script can be run from the commandline directly. It
is setup to run a single shapefile, selected with an integer argument, e.g.:

    Rscript produce_unit_sources.R 10

The above command would run the 10th shapefile from within CONTOURS (assuming
alphabetical ordering).  The main purpose of this option is to facilitate
running each sourcezone separately in a HPC environment (since it is relatively
easy to automatically submit many jobs with different integer arguments).

In either case the working directory must be the directory containing
*'[produce_unit_sources.R](produce_unit_sources.R)'*.

The speed of the code depends heavily on a number of input parameters. If it is too
slow, you can try decreasing the `tsunami_source_cellsize`. More dangerously
you can try increasing the subunitsource_point_spacing parameters, or
increasing the `kajiura_grid_spacing` (the latter only matters if you provide
elevation data). But if the parameters in the last sentence are too coarse
you can expect numerical artefacts.


# Outputs

If the code successfully runs, it will generate: 
* a set of tiff files (one for each unit source) with the computed tsunami
deformation for each unit source (assuming 1m of earthquake slip).
* a pdf file for each source zone, with various plots that can be used to check
that the unit sources and tsunami deformations seem sensible.
* an RDS file for each unit source. This is a native R format file, and contains
the tsunami unit sources as a native R data-structure. It can be useful for
programming and debugging, since it contains the underlying data (such as
sub-unit-source points, exact unit source discretization, etc).

# Tips

* You should visually check that the computed initial conditions seem reasonable.
In early versions of the code, we sometimes observed numerical artefacts in the
computed solution along the trench (manifest as localised spikes in the
deformation). Improvements to the code seem to have dealt with this issue, but
it seems plausible that other artefacts might occur for some input
source-contours  (or you might accidently make a poor choice of input
parameters) -- so we suggest visually checking the outputs.

* If using Kajiura filtering with unit-sources, you can either apply the Kajiura
filter to the unit sources directly before summing them
('filtering-before-combining'), or you can sum the unit sources and
subsequently apply the Kajiura filter ('filtering-after-combining'). The above
code directly supports 'filtering-before-combining'( see codes in the
combine_tsunami_sources folder for 'filtering-after-combining'). Mathematically
the problem is linear, and there should be no difference between these two
cases. However, in practice our Kajiura filtering algorithm involves some
interplation to move from to and from cartesian and spherical coordinates. This
leads to some discretization error, and the approach of
'filtering-before-combining' is numerically more sensitive to this than
'filtering-after-combining'. If this is a problem you might consider using the
`filtering-after-combining' approach. The basic issue that that in the
filtering-before-combining approach, individual unit source deformations can
have steep gradients that would be cancelled by neighbouring sources after
combination. These steep gradients cause relatively high smoothing with the
Kajiura filter. To avoid artefacts any discretization errors in this smoothing
must cancel with those from neighbouring unit source deformations.
