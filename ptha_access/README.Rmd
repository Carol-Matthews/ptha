# **Guide to accessing the 2018 Australian Probabilistic Tsunami Hazard Assessment results**

**Currently these tools are in development, and the study is not complete.** 
* **The data and models referred to below are placeholder examples for internal testing purposes only,
and are not to be used in any real application.**
* **The interfaces are expected to change.**
* **The code should be adjusted to download all data from the NCI [including source-zones + hazard points], to ensure consistency**

This document explains how to access the 2018 Probabilistic Tsunami Hazard
Assessement (PTHA) results. 

# Obtaining basic tsunami hazard information.

## Tsunami peak-stage exceedance rates at sites around Australia

The tsunami 'peak-stage' is the maximum water-level that a particular tsunami
attains in our analysis. Because we ignore tidal variations and assume a
constant mean-sea-level (MSL=0), this is equivalent to the maximum elevation of
the tsunami wave above MSL.

If you only wish to look at the locations of offshore hazard points, with basic
tsunami peak-stage exceedance rate information, then you can simply download
a csv file containing the data here: <http://dapds00.nci.org.au/thredds/fileServer/fj6/PTHA/AustPTHA_1/EVENT_RATES/tsunami_stages_at_fixed_return_periods.csv>. This csv file contains columns:
    * `lon`, `lat` giving the location in longitude/latitude (degrees). 
    * `elev` is the bathymetry at the station (negative = below MSL)
    * `gaugeID` is a real station ID
    * multiple columns with names like `STAGE_XXXX` where XXXX is a number, and 1/XXXX is the exceedance rate. 

        These values corresponds to the tsunami peak-stage which has mean exceedance rate = 1/XXXX. For example, the column `STAGE_100` gives the tsunami peak-stage that is exceeded once every 100 years on average, according to the mean of all the rate models in our logic-tree.
   
    * multiple columns with names like `STAGE_upper_ci_XXXX`. 
    
        These values are similar to the above, but describe the upper limit of the 95% credible interval for the stage with the specified exceedance rate. (i.e. 97.5% quantile)

    * multiple columns with names like `STAGE_lower_ci_XXXX`. 

        These are similar to the above, but describe the lower limit of the 95% credible interval for the stage with the specified exceedance rate. (i.e. 2.5% quantile)

Similar data is available in a shapefile, which can be downloaded here (inside a zip file):
<http://dapds00.nci.org.au/thredds/fileServer/fj6/PTHA/AustPTHA_1/EVENT_RATES/tsunami_stages_at_fixed_return_periods.zip>
Because there is a 10 character limit on shapefile attribute names, the
attributes are renamed in some instances compared with the csv above:
    * `lon`, `lat` giving the location in longitude/latitude (degrees). 
    * `elev` is the bathymetry at the station (negative = below MSL)
    * `gaugeID` is a real station ID
    * `STG_XXXX' is the same as `STAGE_XXXX` described above
    * `STGu_XXXX' is the same as `STAGE_upper_ci_XXXX` described above
    * `STGl_XXXX' is the same as `STAGE_lower_ci_XXXX` described above

At most locations you will find there is high uncertainty in the peak tsunami
size for a given exceedance rates. This is mainly due to high uncertainty in
the frequencies of high-magnitude subduction zone earthquakes. A more detailed
discussion of these topics can be found in the Australian Tsunami Hazard
Modelling Guidelines, which are available here:
<https://knowledge.aidr.org.au/media/5640/tsunami-planning-guidelines.pdf> 

## More detailed exceedance rate information for specific sites

FIXME describe where to obtain the pdf files containing the summary information

# Obtaining detailed information on earthquake events, tsunami initial conditions, and wave time-series

It is possible to obtain initial conditions and time-series for every event in
our analysis.  Combined with the exceedance rate modelling, such inputs can be
used to drive local scale tsunami hazard assessments (i.e. studies which model
actual tsunami inundation).

However, doing this requires interacting with our files via the NCI server,
generally using R code. The steps are described below. Unfortunately they may
be difficult for users who are inexperienced in scientific programming and
linux (and even more advanced users may have difficulties, e.g. in building
netcdf from source). Users doing hazard studies in Australia should
alternatively contact Geoscience Australia directly for assistence in obtaining
the information they require (gareth.davies@ga.gov.au). 


## **Installation**

You need the program R installed (see <https://www.r-project.org/>).


### **Getting a recent version of netcdf**

You also need to install the R package `ncdf4` with OPeNDAP support.  To my
knowledge this may be difficult unless you are running linux (although you can
do this using a virtual machine). I would suggest non-linux users install
an ubuntu virtual machine (e.g. using virtual box) and follow the steps below.

A further complication is that to work with the PTHA outputs on the NCI THREDDS
server you need to build the package with a reasonably recent version of
netcdf-c.  This is due to a bug in netcdf-c versions prior to 4.6.1 (released
in early 2018) that prevented the remote reading of long character strings
with OPeNDAP. We store some earthquake event data as (potentially) long
character strings, and it is essential to be able to read these remotely.

At the time of writing (mid 2018), most users will have to install netcdf-c
from source to access a suitable version.  Source-code for a recent release of
netcdf-c can be obtained from the netcdf github page:
<https://github.com/Unidata/netcdf-c/releases>. You need to follow their
instructions to get it installed. In the authors experience this is not always
easy, but note there is much online troubleshooting information available, and
you can ask for help on the netcdf mailing list.

Suppose you succeed in getting netcdf installed. Next you need to install R's
`ncdf4` package, and specifically tell it to use the newly installed netcdf.
This can be done by downloading the ncdf4 sources here
<https://cran.r-project.org/web/packages/ncdf4/index.html>, and then running a
command similar to the following, in the directory where you have downloaded
the `ncdf4` source package:

    R CMD INSTALL ncdf4_1.16.tar.gz --configure-args="--with-nc-config=/home/username/LocalInstalls/netcdf_for_ptha/install/bin/nc-config"
On ubuntu you might need to prepend `sudo` to the above command, depending on
where you do the installation.  Note you might need to adjust the numbers in
the `ncdf4_1.16.tar.gz` term above to match those of the package you download.
Furthermore, you will need to change the path to nc-config to match the path to
a version of nc-config > 4.6.1.

To confirm that your `ncdf4` installation is using a suitably recent netcdf-c
library, try running the following code:
```{r checkncdf, eval=FALSE}
library(ncdf4)
# This is a file from the PTHA, describing earthquake events on the Kermadec-Tonga
# source-zone. Note I pre-pend [stringlength=4096], which prevents truncation of
# long character strings. This functionality was broken in older netcdf-c versions
test_file = paste0('[stringlength=4096]http://dapds00.nci.org.au/thredds/dodsC/fj6/',
    'PTHA/AustPTHA_1/SOURCE_ZONES/kermadectonga/TSUNAMI_EVENTS/',
    'all_stochastic_slip_earthquake_events_kermadectonga.nc')
# Open it (this will not read everything)
fid = nc_open(test_file, readunlim=FALSE)
# Try to read the event_index_string. This will be artificially truncated if 
# using an old version of netcdf-c
event_index_string = ncvar_get(fid, 'event_index_string')
if(max(nchar(event_index_string)) == 720){
    print('Success! Your ncdf4 install can read large character strings remotely')
}else{
    print('FAIL. Perhaps ncdf4 is linking to an older netcdf-c version?')
}
```
If the above code leads to the `Success! ...` message, then the install is
working, but otherwise you will have to troubleshoot your netcdf-c install (or
your internet connection, or check for a change to the NCI THREDDS server,
etc).

### **Installing rptha***

Finally, you need to install the `rptha` package. This must be built from
source, after obtaining the code from Geoscience Australia's the `PTHA` github
repository. See instructions at https://github.com/GeoscienceAustralia/ptha/R/README.md

### **Installing mapview***
Finally you should install the `mapview` package (to enable some interactive
plots shown below)
```{r installme, eval=FALSE}
install.packages('mapview')
```

## **Unit tests**
Assuming you have installed all the above dependencies, you can run the unit
tests with:
```{r unit_tests, eval=FALSE}
source('test_all.R')
```
This should print a number of 'PASS' statements, and no 'FAIL' statements.
Some of the tests will fail if you haven't installed the dependencies to read
time-series.

## **Usage**

### ***Viewing the locations of hazard points and source zones***

To view the source-zones and hazard points on an interactive map, start
R in the same directory that this file resides in, and do:
```{r interactive_map, eval=FALSE}
source('hazard_points_plot.R')
```

This should open a map in your web browser, containing all unit sources and
hazard points. The latter include DART buoy locations, and a set of points on
the GA250 national bathymetry grid for Australia (because this is a grid, it
contains some points around neighbouring countries as well). 

![hazardpoints1](figure/hazard_point_viewer_screenshot1.png)

Initially, most of the hazard points will be aggregated into coloured circles
containing clusters of hazard points. This is done because it is too slow to
render all hazard points at the same time on the one map. In the above figure,
we see green circles (containing less than 10 hazard points), yellow circles
(containing 10-100 hazard points), and red circles (containing more than 100
hazard points). A number on the circle shows how many hazard points they
contain. The blue dots are individual hazard points, and in the above figure
mostly correspond to the locations of DART buoys.


If you zoom in enough (e.g. below we look at Christmas Island), eventually the circles
containing many points should be replaced by individual hazard points (blue
circles). They can be queried with a mouse click.
![hazardpoints2](figure/hazard_point_viewer_screenshot2.png)

The unit sources appear as a polygonal grid. Individual unit sources can also
be queried. 
![hazardpoints3](figure/hazard_point_viewer_screenshot3c.png)
The controls on the top left of the map can be expanded. These
should allow you to change the background layer, and to turn layers on and off.

### ***Getting metadata on the earthquake events on each source-zone***

To download metadata from the NCI describing the earthquake events on a
particular source-zone, start R in the current directory, and do:
```{r get_metadata}
# Import the functions
source('get_PTHA_results.R')

# Example: get metadata for the puysegur source_zone
puysegur = get_source_zone_events_data('puysegur')
```

This variable `puysegur` is now an R `list`, which contains two `data.frame`'s: 
* `puysegur$unit_source_statistics` contains summary statistics about the unit-sources. 
For each unit source this gives the centroid `lon` and `lat` and `depth`; the unit source
dimensions `length` and `width`; the rupture source mechanism (`strike`, `dip`, `rake`);
and indices `downdip_number`, `alongstrike_number`, and `subfault_number` which give
information of the placement of the unit source on the grid of all unit sources. 
```{r metadata_infoA}
# Get the names of all summary statistics
names(puysegur$unit_source_statistics)

# Get the table dimensions
dim(puysegur$unit_source_statistics)

# Print rows 1 and 2
puysegur$unit_source_statistics[1:2,]

# File paths in the above table describe the location of key files *at the time
# the model was run*. 
# This may not be the same as the location of the files that the user downloads
# (because in general, we cannot provide download access to our computational
# drives). 
# However, the functions we provide to access the data will translate filenames
# to the web-accessible versions, as required. 
```

* `puysegur$events` contains summary statistics about the earthquake events.
The most important are the moment magnitude `Mw`, the earthquake slip (either a
single numeric `slip` for uniform slip events; or for variable slip events, a
character `event_slip_string` with slip values for each unit source separated
by an underscore), and the `event_index_string`. The latter can be used to
determine which unit-sources are included in the earthquake (the integers in
`event_index_string` correspond to `subfault_number`'s in the
`unit_source_statistics`, separated by a `-` character).

```{r metadata_infoB}
# Print the names of all event summary statistics
names(puysegur$events)

# Get the table dimensions
dim(puysegur$events)

# Print rows 200 and 201
puysegur$events[200:201, ]
```

### ***Getting initial conditions for a single earthquake-tsunami event***

Suppose we want to get the initial conditions for the earthquake event on row
240 of `puysegur$events`.  (By initial conditions, we mean the initial water
surface perturbation -- the velocity is treated as zero). The metadata for event 240 is:
```{r event240}
puysegur$events[240,]
```
To get its initial condition, do:
```{r raster_event240, fig.width=6, fig.height=8}
# Get the initial condition as a geo-referenced raster
initial_condition_240 = get_initial_condition_for_event(puysegur, 240)

## The raster can be save as a geotif for use in other software, with:
# writeRaster(initial_conditions, 'my_output_filename.tif')

# Make a plot
plot(initial_condition_240, main='Initial water surface deformation, event 240, Puysegur')

```

The function `get_initial_condition_for_event` used above will download the
required data from the web and save it in the folder
`SOURCE_ZONES/puysegur/EQ_SOURCE/Unit_source_data/puysegur`. Subsequently, the
function will check whether the required files exist in that folder, and only
download those that it needs. However, you can force the function to download
the files (and overwrite any existing ones) by adding the argument
`force_file_download=TRUE` (by default the latter is `FALSE`). This is useful
if the NCI analysis has been updated.
```{r event240B, eval=FALSE}
# Get the initial condition as a geo-referenced raster, forcing download of
# all files from NCI irrespective of whether they exist on the current
# machine
initial_condition_240 = get_initial_condition_for_event(puysegur, 240, force_file_download=TRUE)
```


### ***Getting hazard curves at a particular hazard point***

FIXME: To do -- I still need to make the data on NCI to facilitate this.

The user must be aware that at some locations, some modelled waves will violate
the assumptions underlying our linear tsunami model. Furthermore, in some
regions our coarse resolution model (1 arc minute) and elevation data
(GA250/GEBCO2014) may have insufficient resolution or accuracy to model the
tsunami well. While we cannot a-priori identify such points, problems are most
likely to arise close to the coast and in shallower waters. For modelling
purposes we strongly encourage the use of points well offshore in deep water
(preferably with wave heights of interest not exceeding a few percent of the
water depth). To help ensure such points are available, the current PTHA
includes points along a 1000m depth contour and gridded lon-lat points
extending well offshore, in addition to the 100m depth contour points.


### ***Finding earthquake events within a particular wave-height range at a particular hazard point***

FIXME: To do -- I still need to make the data on NCI to facilitate this


### ***Extracting the tsunami time-series for a particular event at a particular hazard point***

Here we show how to read a flow time-series for a given earthquake event, at a
given hazard point. To do this, you have to know the hazard point ID, which can
be found by clicking on the hazard point in the interactive map above (see the
ID number). 

The data is downloaded from the NCI.

*Recall that this requires that ncdf4 and rptha are installed appropriately,
see the installation section above.*

```{r getflow, fig.width=5, fig.height=5}
# Get stage, uh, vh time-series at DART gauges 55015 and 55042
# To find the ID's, look on the interactive hazard-point map.
model_240 = get_flow_time_series_at_hazard_point(puysegur, 
    event_ID=240, 
    hazard_point_ID=c(55015.4, 55042.4))
# Should have a 'time' vector, and 'flow' list, and a 'locations' data.frame
names(model_240)
# The 'flow' list should have one matrix for each gauge. 
names(model_240$flow)
# Alternatively the user can keep 'flow' as an array with the first dimension
# size equal to the number of gauges, by passing the argument 'unpack_to_list=FALSE'
# The latter option may be more efficient for some computations.

# By default for each gauge, model_240$flow[["gauge_id"]] is a 3D array. 
# The first dimension is always length 1, the second dimension has length
# equal to the number of time-steps, and the third dimension is of length
# three -- with 1 = Stage, 2 = UH, 3 = VH
dim(model_240$flow[['55015.4']])

# Example plot of stage
plot(model_240$time, model_240$flow[['55015.4']][1,,1], t='l', 
    xlim=c(0,10000), xlab='Seconds after earthquake', ylab='Stage (m)')
points(model_240$time, model_240$flow[['55042.4']][1,,1], t='l', 
    col='red')
legend('topright', c('55015.4', '55042.4'), col=c('black', 'red'), lty=c(1,1))

title('Some stage gauges for event 240')
```
