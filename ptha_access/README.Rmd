# **Guide to accessing the 2018 Australian Probabilistic Tsunami Hazard Assessment (PTHA) results**

# ***NOTE: Currently the study is incomplete, and results available here may change without warning***

We provide access to basic tsunami hazard information in easy-to-use csv and
shapefile formats. This information is useful to get a high-level overview of
the PTHA results.

We also provide access to detailed information for every event in our analysis:
earthquake discretization, tsunami initial condition, and wave time-series at
a large set of points in the ocean ('hazard points'). This information is
useful for site-specific tsunami hazard studies (which use it for model
'boundary conditions' and to estimate how often hazardous tsunamis might
occur). To access this information users will need to install a range of
software which allows working with the PTHA data on the NCI THREDDS server. 

# Obtaining basic tsunami hazard information.


## Obtaining tsunami peak-stage exceedance-rates at sites around Australia

The tsunami 'peak-stage' is the maximum water-level that a particular tsunami
attains at a particular location. In the current analysis we ignore tidal
variations and assume a constant mean-sea-level (MSL=0), so the 'peak-stage' is
equivalent to the maximum elevation of the tsunami wave above MSL. This gives an
idea of how 'big' the tsunami is.

In the 2018 PTHA, this information is stored at a set of points in the ocean.
These points are termed 'hazard points' because we provide the hazard
information at these sites. (The wave time-series for every event can also be
obtained at all hazard points using methods described later in this document).

The peak-stage exceedance-rates describe 'how often' tsunami events occur with
peak-stage above a particular threshold value. For example, you could ask how often
peak-stages above 0.5m (or 2.0m) occur, in terms of the average number of events each year
at a particular site. At most locations there would be less than one event each year, so
the exceedance rates are typically small numbers (e.g. an exceedance-rate of
0.002=1/500 would correspond to one event every 500 years on average).
Obviously this kind of information is important for understanding tsunami
hazards. The simplest way to examine the tsunami peak-stage exceedance-rates in
the 2018 PTHA is to [download this csv file](http://dapds00.nci.org.au/thredds/fileServer/fj6/PTHA/AustPTHA_1/EVENT_RATES/tsunami_stages_at_fixed_return_periods.csv).
This csv file contains the following columns:

* `lon`, `lat` give the hazard point location in longitude/latitude (degrees). 

* `elev` is the bathymetry at the hazard point (negative = below MSL)

* `gaugeID` is a real hazard point ID

* multiple columns with names like `STAGE_XXXX` where XXXX is a number, and 1/XXXX is the exceedance-rate. These values corresponds to the tsunami peak-stage which has mean exceedance-rate = 1/XXXX. For example, the column `STAGE_100` gives the tsunami peak-stage that is exceeded once every 100 years on average, according to the mean of all the rate models in our logic-tree.

* multiple columns with names like `STAGE_upper_ci_XXXX`. These values are similar to the above, but describe the upper limit of the 95% credible interval for the stage with the specified exceedance-rate. (i.e. 97.5% quantile)

* multiple columns with names like `STAGE_lower_ci_XXXX`. These are similar to the above, but describe the lower limit of the 95% credible interval for the stage with the specified exceedance-rate. (i.e. 2.5% quantile)

[Similar data is available in shapefile format here](http://dapds00.nci.org.au/thredds/fileServer/fj6/PTHA/AustPTHA_1/EVENT_RATES/tsunami_stages_at_fixed_return_periods.zip). You will need to unzip the file after download.
A shortcoming of the shapefile format is that there is a 10 character limit on
attribute names. Therefore the attributes are renamed in some instances, as
compared with the above csv:

* `lon`, `lat` give the location in longitude/latitude (degrees). 

* `elev` is the bathymetry at the hazard point (negative = below MSL)

* `gaugeID` is a real hazard point ID

* `STG_XXXX` is the same as `STAGE_XXXX` described above

* `STGu_XXXX` is the same as `STAGE_upper_ci_XXXX` described above

* `STGl_XXXX` is the same as `STAGE_lower_ci_XXXX` described above

At most hazard points you will find there is large uncertainty in the
peak-stage for a given exceedance-rate. This is mainly due to large uncertainty
in the frequencies of high-magnitude subduction zone earthquakes. A more
detailed discussion of these topics can be found in the 
[Australian Tsunami Hazard Modelling Guidelines](https://knowledge.aidr.org.au/media/5640/tsunami-planning-guidelines.pdf).

## Obtaining more detailed exceedance-rate information for specific sites

FIXME describe where to obtain the pdf files containing the summary information

## Interpreting exceedance-rate information

The peak-stage exceedance-rates vary from site to site, depending on exposure
to earthquake-generated tsunamis. For a given exceedance-rate, there is also a
general tendency for the tsunami size to increase in shallower water. Such
'shoaling' is a well known property of ocean waves. 

The model results are not expected to be accurate everywhere, but **in general
results far offshore and in deep water are expected to be higher quality than
nearshore results**. The reasons are:

* Our tsunami model has a spatial grid size of 1 arc minute (around 1.8 km), 
and is run on relatively coarse elevation data (a combination of the 
[Australian Bathymetry and Topography Grid 2009](http://www.ga.gov.au/metadata-gateway/metadata/record/gcat_67703)
product, and the global [GEBCO
2014](https://www.gebco.net/data_and_products/gridded_bathymetry_data/) bathymetry grid).
While appropriate for modelling oceanic-scale tsunami propagation, it is not
expected to accurately model tsunamis near the coast and in shallow waters.

* At locations where wave heights become an appreciable fraction of the water depth, 
the modelled waves will violate the assumptions underlying our linear tsunami
model. This is most likely to be a problem in shallow waters where the tsunami
wave height becomes non-negligable compared with the water depth. 

Because of this, **for modelling purposes we strongly encourage the use of
points well offshore in deep water** (preferably with wave heights of interest
not exceeding a few percent of the water depth). Nearshore points should only
be used as a rough guide to possible tsunami wave heights, and should be
refined in future using higher resolution models and data. 

The above points might lead non-specialist to question the point of this PTHA,
given that for risk management purposes the tsunami inundation is of most
interest. The key reason for developing an 'offshore' PTHA is that it provides
essential input data to support the high-resolution models required for tsunami
risk management. The tsunami scenarios and associated exceedance-rates provided
in this PTHA will be used as 'boundary conditions' to drive the site-specific
high resolution tsunami inundation models. 

# Obtaining detailed information on earthquake events, tsunami initial conditions, and wave time-series

For every event in our analysis we provide earthquake information, tsunami
initial conditions, and wave time-series at every hazard point. Combined
with the exceedance-rate modelling, such inputs can be used to drive local
scale tsunami hazard assessments (i.e. studies which model tsunami inundation).

To access these results the user needs to interact with our files via the NCI
THREDDS server. We provide R scripts to facilitate this, and the process is
described below. A range of software must be installed to run these codes,
[as described here](INSTALL.md)

Unfortunately the installation and data extraction process may be challenging
for users with limited experience in scientific programming and linux. Users
doing tsunami hazard studies **in Australia** can alternatively contact
Geoscience Australia directly if they have difficulty with any of these steps
(please email Gareth Davies at gareth.davies@ga.gov.au). 

## **Usage**

Make sure you have successfully installed the software [as described here](INSTALL.md), 
and that the unit-tests pass.

### ***Viewing the locations of hazard points and source zones***

It is possible to view the hazard points from an interactive map in R.

To view the source-zones and hazard points on an interactive map, start
R in the same directory that the [hazard_points_plot.R](hazard_points_plot.R)
file resides in, and do:
```{r interactive_map, eval=FALSE}
source('hazard_points_plot.R')
```

The should open a map in your web browser, containing all unit sources and
hazard points. The latter include DART buoy locations, and a set of points on
the GA250 national bathymetry grid for Australia (because this is a grid, it
contains some points around neighbouring countries as well). 

The first time you run this code it will download a range of datasets to your
machine. This might take a minute or more, depending on your internet connection.
Future runs will read the data from your machine, so should be faster. 


![hazardpoints1](figure/hazard_point_viewer_screenshot1.png)

Initially, most of the hazard points will be aggregated into coloured circles
containing clusters of hazard points. This is done because it is too slow to
render all hazard points at the same time on the one map. In the above figure,
we see green circles (containing less than 10 hazard points), yellow circles
(containing 10-100 hazard points), and red circles (containing more than 100
hazard points). A number on the circle shows how many hazard points they
contain. There are also a few individual hazard points (which are far from
others), and in the above figure they mostly correspond to the locations of DART
buoys.

If you zoom in enough (e.g. below we look at Christmas Island), eventually the circles
containing many points should be replaced by individual hazard points
(circles). They can be queried with a mouse click. For each point, we store
basic stage-vs-exceedance-rate information, as was discussed above.
![hazardpoints2](figure/hazard_point_viewer_screenshot2.png)

The unit sources appear as a polygonal grid. Individual unit sources can also
be queried (e.g. to learn the name of the source-zone in our analysis) 
![hazardpoints3](figure/hazard_point_viewer_screenshot3c.png)
The controls on the top left of the map can be expanded as shown in the figure.
These should allow you to change the background layer, and to turn layers on
and off.

### ***Getting metadata on the earthquake events on each source-zone***

Earthquake event metadata is accessed on a per-source-zone basis. In a typical
application you would use the detailed exceedance rate plots discussed above
to identify the main source-zones of interest for a particular site. Below
we show an example using the `puysegur` source-zone, which is located just south
of New Zealand, to the north of Macquarie Island.

To download metadata from the NCI describing the earthquake events on a
particular source-zone, start R in the current directory, and do:
```{r get_metadata}
# Import the functions
source('get_PTHA_results.R')

# Example: get metadata for the puysegur source_zone
puysegur = get_source_zone_events_data('puysegur')
```

This variable `puysegur` is now an R `list`, which contains two `data.frame`'s
summarising the source-zone geometry and the earthquake events, and a character
vector giving the associated tide-gauge files (where tsunami time-series are
stored): 
* `puysegur$unit_source_statistics` contains summary statistics about the unit-sources. 
For each unit source this gives the centroid `lon` and `lat` and `depth`; the unit source
dimensions `length` and `width`; the rupture source mechanism (`strike`, `dip`, `rake`);
and indices `downdip_number`, `alongstrike_number`, and `subfault_number` which give
information of the placement of the unit source on the grid of all unit sources.
```{r metadata_infoA}
# Get the names of all summary statistics
names(puysegur$unit_source_statistics)

# Get the table dimensions
dim(puysegur$unit_source_statistics)

# Print rows 1 and 2
puysegur$unit_source_statistics[1:2,]

# File paths in the above table describe the location of key files *at the time
# the model was run*. 
# This is not always identical to the of the files that the user downloads
# (because in general, we cannot provide download access to our computational
# drives). However, it will be closely related.
# The functions we provide to access the data automatically translate filenames
# to the web-accessible versions. 
```

* `puysegur$events` contains summary statistics about the earthquake events.
The most important are the moment magnitude `Mw`, the "variable shear modulus"
moment magnitude `variable_mu_Mw`, the `event_slip_string` (a character with
slip values for each unit source separated by an underscore), and the
`event_index_string`. The latter can be used to determine which unit-sources
are included in the earthquake (the integers in `event_index_string` correspond
to `subfault_number`'s in the `unit_source_statistics`, separated by a `-`
character). 

```{r metadata_infoB}
# Print the names of all event summary statistics
names(puysegur$events)

# Get the table dimensions
dim(puysegur$events)
```

Another useful event-table variable is the `weight_with_nonzero_rate`. This
gives the fraction of the exceedance-rate models in the logic tree that suggest
the event could possibly occur, according to the event magnitude. Values close
to 1.0 indicate "a high fraction of our rate models suggest the event could
occur, given a long enough time-frame". On the other hand, values close to 0.0
indicate that "a high fraction of our rate models suggest the event would never
occur", with zero corresponding to an impossible event (i.e. according to the
model).

While there are many ways to investigate the event table, a simple approach is
to just print some rows. In general low row-indices will correspond to low
magnitudes, and high indices to high magnitudes.
```{r metadata_infoC}

# Print some rows (we choose 3050, 3051, 3052)
puysegur$events[3050:3052, ]
```


### ***Getting initial conditions for a single earthquake-tsunami event***

Suppose we want to get the initial conditions for the earthquake event on row
3051 of `puysegur$events`.  (By initial conditions, we mean the initial water
surface perturbation -- the velocity is treated as zero). The metadata for event 3051 is:
```{r eventXXX}
row_index = 3051 # Use this variable to refer to event 3051
puysegur$events[row_index,]
```
To get its initial condition, do:
```{r raster_eventXXX, fig.width=6, fig.height=8}
# Get the initial condition as a geo-referenced raster
initial_condition = get_initial_condition_for_event(puysegur, row_index)

## The raster can be save as a geotif for use in other software, with:
# writeRaster(initial_conditions, 'my_output_filename.tif')

# Make a plot
plot(initial_condition, main='Initial water surface deformation \n for the example event, Puysegur')

```

The function `get_initial_condition_for_event` used above will download the
required data from the web and save it in the folder
`SOURCE_ZONES/puysegur/EQ_SOURCE/Unit_source_data/puysegur`. Subsequently, the
function will check whether the required files exist in that folder, and only
download those that it needs. However, you can force the function to download
the files (and overwrite any existing ones) by adding the argument
`force_file_download=TRUE` (by default the latter is `FALSE`). This is useful
if the NCI analysis has been updated.
```{r eventXXXB, eval=FALSE}
# Get the initial condition as a geo-referenced raster, forcing download of
# all files from NCI irrespective of whether they exist on the current
# machine
initial_condition = get_initial_condition_for_event(puysegur, row_index, force_file_download=TRUE)
```


### ***Getting hazard curves at a particular hazard point***

FIXME: Integrate with above discussion. Consider showing how to download numeric
curve values for a particular point.


### ***Finding earthquake events within a particular wave-height range at a particular hazard point***

FIXME: 

### ***Extracting the tsunami time-series for a particular event at a particular hazard point***

Here we show how to read a flow time-series for a given earthquake event, at a
given hazard point. To do this, you have to know the hazard point `gaugeID`,
which can be found by examining the peak-stage vs exceedance-rate datasets (csv
and shapefile), or by using the interactive hazard point viewer above. (***In the
latter case, please do not confuse this with the Feature ID that is shown by
default in the interactive map - I would like to remove this field, but do not
yet know how/if it can be done!***). 

```{r getflow, fig.width=5, fig.height=5}
# Get stage, uh, vh time-series at DART gauges 55015 and 55042
# To find the ID's, look on the interactive hazard-point map.
model_ts = get_flow_time_series_at_hazard_point(puysegur, 
    event_ID=row_index, 
    hazard_point_ID=c(55015.4, 55042.4))
# Should have a 'time' vector, and 'flow' list, and a 'locations' data.frame, as
# well as the 'events' data
names(model_ts)
# The 'flow' list should have one matrix for each gauge. 
names(model_ts$flow)
# Alternatively the user can keep 'flow' as an array with the first dimension
# size equal to the number of gauges, by passing the argument 'unpack_to_list=FALSE'
# The latter option may be more efficient for some computations.

# By default for each gauge, model_ts$flow[["gauge_id"]] is a 3D array. 
# The first dimension is always length 1, the second dimension has length
# equal to the number of time-steps, and the third dimension is of length
# three -- with 1 = Stage, 2 = UH, 3 = VH
dim(model_ts$flow[['55015.4']])

# Example plot of stage
plot(model_ts$time, model_ts$flow[['55015.4']][1,,1], t='l', 
    xlim=c(0,10000), xlab='Seconds after earthquake', ylab='Stage (m)',
    ylim=c(-0.1, 0.1))
points(model_ts$time, model_ts$flow[['55042.4']][1,,1], t='l', 
    col='red')
legend('topright', c('55015.4', '55042.4'), col=c('black', 'red'), lty=c(1,1))

title('Stage time-series for the event at 2 gauges')
```

To export the flow time-series to a csv, you can do something like this for
the station of interest:
```{r exportToCSV}
# Name the site
sitename = '55015.4'
# Note you can get a vector with all names using the comment:
#    names(model_ts$flow)
# and this will allow programatically working with the names

# Make a data.frame with the required data
site_flow = data.frame(
    time=model_ts$time, 
    stage = model_ts$flow[[sitename]][1,,1],
    uh = model_ts$flow[[sitename]][1,,2],
    vh = model_ts$flow[[sitename]][1,,3])

# Save it to a csv
output_file = paste0('output_gauge_data_puysegur_event_', row_index, '_station_', 
    sitename, '.csv')
write.csv(site_flow, output_file, row.names=FALSE)

```
